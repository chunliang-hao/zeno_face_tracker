{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare_dataset\n",
    "\n",
    "Track Zeno's face images using an [exisiting tool](https://github.com/IntelligentBehaviourUnderstandingGroup/dlib_and_chehra_stuff) and prepare them for manual annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "try:\n",
    "    from ConfigParser import ConfigParser    # If using Python 2.7\n",
    "except ImportError:\n",
    "    from configparser import ConfigParser    # If using Python 3.5\n",
    "config = ConfigParser()\n",
    "config.read('prepare_dataset.ini')\n",
    "sys.path.append(os.path.realpath(config.get('facial_landmark_tracker', 'repository_path')))\n",
    "import ibug_face_tracker\n",
    "from zeno_face_tracker_helpers import *\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialise the landmark localiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facial landmark localiser initialised.\n"
     ]
    }
   ],
   "source": [
    "tracker = ibug_face_tracker.FaceTracker(os.path.realpath(config.get('facial_landmark_tracker', \n",
    "                                                                    'ert_model_path')), \n",
    "                                        os.path.realpath(config.get('facial_landmark_tracker', \n",
    "                                                                    'auxiliary_model_path')))\n",
    "tracker.face_detection_scale = config.getfloat('facial_landmark_tracker', 'face_detection_scale')\n",
    "tracker.minimum_face_size = config.getint('facial_landmark_tracker', 'minimum_face_size')\n",
    "tracker.hard_failure_threshold = -1e6\n",
    "tracker.estimate_head_pose = False\n",
    "tracker.eye_iterations = 0\n",
    "print('Facial landmark localiser initialised.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Localise Facial Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 images to be processed.\n",
      "112 images have been processed.\n",
      "219 images have been processed.\n",
      "334 images have been processed.\n",
      "450 images have been processed.\n",
      "566 images have been processed.\n",
      "683 images have been processed.\n",
      "796 images have been processed.\n",
      "921 images have been processed.\n",
      "1027 images have been processed.\n",
      "1141 images have been processed.\n",
      "Done, all 1200 images have been processed, 1048 of which have landmarks localised.\n"
     ]
    }
   ],
   "source": [
    "# Enumerate jobs\n",
    "source_images = sorted(glob.glob(os.path.realpath(os.path.join('./dataset', 'cam*', '*.png'))))\n",
    "source_images = [x for x in source_images if '.pts.png' not in x]\n",
    "print('%d images to be processed.' % len(source_images))\n",
    "\n",
    "# Get landmarks\n",
    "successes = 0\n",
    "last_check_time = time.time()\n",
    "for idx, image_path in enumerate(source_images):\n",
    "    image = cv2.imread(image_path)\n",
    "    tracker.reset()\n",
    "    tracker.track(image)\n",
    "    if tracker.has_facial_landmarks:\n",
    "        pts_path = os.path.splitext(image_path)[0] + '.init.pts'\n",
    "        save_pts(pts_path, tracker.facial_landmarks)\n",
    "        tracker.plot_current_result(image)\n",
    "        rendering_path = pts_path + '.png'\n",
    "        cv2.imwrite(rendering_path, image)\n",
    "        successes += 1\n",
    "    current_time = time.time()\n",
    "    if current_time - last_check_time > 10.0:\n",
    "        last_check_time = current_time\n",
    "        print('%d images have been processed.' % (idx + 1))\n",
    "print('Done, all %d images have been processed, %d of which have landmarks localised.' % \n",
    "      (len(source_images), successes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
